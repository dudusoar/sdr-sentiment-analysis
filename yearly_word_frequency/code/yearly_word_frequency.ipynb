{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015_word</th>\n",
       "      <th>2015_frequency</th>\n",
       "      <th>2016_word</th>\n",
       "      <th>2016_frequency</th>\n",
       "      <th>2017_word</th>\n",
       "      <th>2017_frequency</th>\n",
       "      <th>2018_word</th>\n",
       "      <th>2018_frequency</th>\n",
       "      <th>2019_word</th>\n",
       "      <th>2019_frequency</th>\n",
       "      <th>2020_word</th>\n",
       "      <th>2020_frequency</th>\n",
       "      <th>2021_word</th>\n",
       "      <th>2021_frequency</th>\n",
       "      <th>2022_word</th>\n",
       "      <th>2022_frequency</th>\n",
       "      <th>2023_word</th>\n",
       "      <th>2023_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flying</td>\n",
       "      <td>4.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>10.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>137.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>53.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>148.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>140.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>214.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>477</td>\n",
       "      <td>robot</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>idea</td>\n",
       "      <td>3.0</td>\n",
       "      <td>people</td>\n",
       "      <td>7.0</td>\n",
       "      <td>food</td>\n",
       "      <td>51.0</td>\n",
       "      <td>people</td>\n",
       "      <td>23.0</td>\n",
       "      <td>people</td>\n",
       "      <td>62.0</td>\n",
       "      <td>people</td>\n",
       "      <td>56.0</td>\n",
       "      <td>one</td>\n",
       "      <td>73.0</td>\n",
       "      <td>people</td>\n",
       "      <td>212</td>\n",
       "      <td>would</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would</td>\n",
       "      <td>3.0</td>\n",
       "      <td>though</td>\n",
       "      <td>4.0</td>\n",
       "      <td>people</td>\n",
       "      <td>39.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>17.0</td>\n",
       "      <td>one</td>\n",
       "      <td>61.0</td>\n",
       "      <td>one</td>\n",
       "      <td>49.0</td>\n",
       "      <td>like</td>\n",
       "      <td>71.0</td>\n",
       "      <td>would</td>\n",
       "      <td>198</td>\n",
       "      <td>people</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drone</td>\n",
       "      <td>3.0</td>\n",
       "      <td>car</td>\n",
       "      <td>4.0</td>\n",
       "      <td>job</td>\n",
       "      <td>39.0</td>\n",
       "      <td>work</td>\n",
       "      <td>16.0</td>\n",
       "      <td>get</td>\n",
       "      <td>61.0</td>\n",
       "      <td>like</td>\n",
       "      <td>39.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>68.0</td>\n",
       "      <td>get</td>\n",
       "      <td>178</td>\n",
       "      <td>one</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cool</td>\n",
       "      <td>2.0</td>\n",
       "      <td>love</td>\n",
       "      <td>3.0</td>\n",
       "      <td>human</td>\n",
       "      <td>34.0</td>\n",
       "      <td>food</td>\n",
       "      <td>15.0</td>\n",
       "      <td>like</td>\n",
       "      <td>57.0</td>\n",
       "      <td>thing</td>\n",
       "      <td>39.0</td>\n",
       "      <td>people</td>\n",
       "      <td>67.0</td>\n",
       "      <td>thing</td>\n",
       "      <td>157</td>\n",
       "      <td>cute</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>see</td>\n",
       "      <td>2.0</td>\n",
       "      <td>might</td>\n",
       "      <td>3.0</td>\n",
       "      <td>get</td>\n",
       "      <td>33.0</td>\n",
       "      <td>job</td>\n",
       "      <td>15.0</td>\n",
       "      <td>thing</td>\n",
       "      <td>55.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>35.0</td>\n",
       "      <td>job</td>\n",
       "      <td>67.0</td>\n",
       "      <td>one</td>\n",
       "      <td>153</td>\n",
       "      <td>like</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>want</td>\n",
       "      <td>3.0</td>\n",
       "      <td>one</td>\n",
       "      <td>30.0</td>\n",
       "      <td>would</td>\n",
       "      <td>11.0</td>\n",
       "      <td>would</td>\n",
       "      <td>48.0</td>\n",
       "      <td>get</td>\n",
       "      <td>33.0</td>\n",
       "      <td>would</td>\n",
       "      <td>66.0</td>\n",
       "      <td>like</td>\n",
       "      <td>151</td>\n",
       "      <td>delivery</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pretty</td>\n",
       "      <td>3.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>29.0</td>\n",
       "      <td>like</td>\n",
       "      <td>10.0</td>\n",
       "      <td>take</td>\n",
       "      <td>46.0</td>\n",
       "      <td>job</td>\n",
       "      <td>33.0</td>\n",
       "      <td>food</td>\n",
       "      <td>59.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>148</td>\n",
       "      <td>get</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hipster</td>\n",
       "      <td>1.0</td>\n",
       "      <td>need</td>\n",
       "      <td>3.0</td>\n",
       "      <td>like</td>\n",
       "      <td>29.0</td>\n",
       "      <td>also</td>\n",
       "      <td>10.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>40.0</td>\n",
       "      <td>would</td>\n",
       "      <td>30.0</td>\n",
       "      <td>get</td>\n",
       "      <td>59.0</td>\n",
       "      <td>food</td>\n",
       "      <td>135</td>\n",
       "      <td>coco</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>video</td>\n",
       "      <td>1.0</td>\n",
       "      <td>one</td>\n",
       "      <td>3.0</td>\n",
       "      <td>thing</td>\n",
       "      <td>26.0</td>\n",
       "      <td>get</td>\n",
       "      <td>10.0</td>\n",
       "      <td>food</td>\n",
       "      <td>39.0</td>\n",
       "      <td>cute</td>\n",
       "      <td>29.0</td>\n",
       "      <td>thing</td>\n",
       "      <td>59.0</td>\n",
       "      <td>job</td>\n",
       "      <td>133</td>\n",
       "      <td>make</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  2015_word  2015_frequency 2016_word  2016_frequency 2017_word   \n",
       "0    flying             4.0     robot            10.0     robot  \\\n",
       "1      idea             3.0    people             7.0      food   \n",
       "2     would             3.0    though             4.0    people   \n",
       "3     drone             3.0       car             4.0       job   \n",
       "4      cool             2.0      love             3.0     human   \n",
       "5       see             2.0     might             3.0       get   \n",
       "6      nice             1.0      want             3.0       one   \n",
       "7      good             1.0    pretty             3.0  delivery   \n",
       "8   hipster             1.0      need             3.0      like   \n",
       "9     video             1.0       one             3.0     thing   \n",
       "\n",
       "   2017_frequency 2018_word  2018_frequency 2019_word  2019_frequency   \n",
       "0           137.0     robot            53.0     robot           148.0  \\\n",
       "1            51.0    people            23.0    people            62.0   \n",
       "2            39.0  delivery            17.0       one            61.0   \n",
       "3            39.0      work            16.0       get            61.0   \n",
       "4            34.0      food            15.0      like            57.0   \n",
       "5            33.0       job            15.0     thing            55.0   \n",
       "6            30.0     would            11.0     would            48.0   \n",
       "7            29.0      like            10.0      take            46.0   \n",
       "8            29.0      also            10.0  delivery            40.0   \n",
       "9            26.0       get            10.0      food            39.0   \n",
       "\n",
       "  2020_word  2020_frequency 2021_word  2021_frequency 2022_word   \n",
       "0     robot           140.0     robot           214.0     robot  \\\n",
       "1    people            56.0       one            73.0    people   \n",
       "2       one            49.0      like            71.0     would   \n",
       "3      like            39.0  delivery            68.0       get   \n",
       "4     thing            39.0    people            67.0     thing   \n",
       "5  delivery            35.0       job            67.0       one   \n",
       "6       get            33.0     would            66.0      like   \n",
       "7       job            33.0      food            59.0  delivery   \n",
       "8     would            30.0       get            59.0      food   \n",
       "9      cute            29.0     thing            59.0       job   \n",
       "\n",
       "   2022_frequency 2023_word  2023_frequency  \n",
       "0             477     robot            82.0  \n",
       "1             212     would            22.0  \n",
       "2             198    people            21.0  \n",
       "3             178       one            21.0  \n",
       "4             157      cute            18.0  \n",
       "5             153      like            17.0  \n",
       "6             151  delivery            15.0  \n",
       "7             148       get            15.0  \n",
       "8             135      coco            14.0  \n",
       "9             133      make            14.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = 'word_frequency_by_year_2015_2023.xlsx'\n",
    "df = pd.read_excel(file_path, sheet_name='Sheet1')\n",
    "df.head() \n",
    "\n",
    "# List of columns to be converted to integer\n",
    "frequency_columns = ['2015_frequency', '2016_frequency', '2017_frequency', \n",
    "                     '2018_frequency', '2019_frequency', '2020_frequency', \n",
    "                     '2021_frequency', '2022_frequency', '2023_frequency']\n",
    "\n",
    "# Convert each frequency column to integer, handling non-integer values (errors='coerce' will convert them to NaN)\n",
    "for col in frequency_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce', downcast='integer')\n",
    "\n",
    "# Drop rows where all frequency columns are NaN\n",
    "df= df.dropna(subset=frequency_columns, how='all')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list1 = ['never', 'dont','cant','wont', 'would', 'could','might', 'may', 'though', 'without','u','im','theyre', 'that','also','yeah']\n",
    "drop_list2 = ['gp','hipster', 'one', 'thing','lol', 'many', 'still', 'sure']\n",
    "drop_list3 = ['someone', 'anyone']\n",
    "drop_list4 = ['think','going']\n",
    "drop_list5 = ['robot','people']\n",
    "drop_list3 = ['fantasticbeautiful', 'u', 'r', 'hahahahahahahahahahahhahahaa', 'f', 'b',\n",
    "              'interdisciplinary', 'd', 'p', 'w', 'trackeralarmcamerayou', 'wwwstarshipxyzfollow',\n",
    "              'n', 'neighborhoodwatch', 'v', 'x', 'objectsparticularly', 'stationsgroceriy',\n",
    "              'y', 'unleasheduntrained', 'o', 'h', 'j', 'l', 'e', 'm', 'northamptonshire',\n",
    "              'wonderfulanother', 'wisconsinmadison', 'westwooduclathem', 'operatingmonitoringdriving',\n",
    "              'observingtracking', 'scaredconservative', 'anthropomorphising', 'unemploymentthese',\n",
    "              'c', 'stolenbotknapped', 'pedestrianscyclist', 'catastrophically', 'multiplicatively',\n",
    "              'watchvzsmttvytqaa','pm']\n",
    "drop_list = drop_list1 + drop_list2 + drop_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015_word</th>\n",
       "      <th>2015_frequency</th>\n",
       "      <th>2016_word</th>\n",
       "      <th>2016_frequency</th>\n",
       "      <th>2017_word</th>\n",
       "      <th>2017_frequency</th>\n",
       "      <th>2018_word</th>\n",
       "      <th>2018_frequency</th>\n",
       "      <th>2019_word</th>\n",
       "      <th>2019_frequency</th>\n",
       "      <th>2020_word</th>\n",
       "      <th>2020_frequency</th>\n",
       "      <th>2021_word</th>\n",
       "      <th>2021_frequency</th>\n",
       "      <th>2022_word</th>\n",
       "      <th>2022_frequency</th>\n",
       "      <th>2023_word</th>\n",
       "      <th>2023_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flying</td>\n",
       "      <td>4.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>10.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>137.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>53.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>148.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>140.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>214.0</td>\n",
       "      <td>robot</td>\n",
       "      <td>477</td>\n",
       "      <td>robot</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>good</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pretty</td>\n",
       "      <td>3.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>29.0</td>\n",
       "      <td>like</td>\n",
       "      <td>10.0</td>\n",
       "      <td>take</td>\n",
       "      <td>46.0</td>\n",
       "      <td>job</td>\n",
       "      <td>33.0</td>\n",
       "      <td>food</td>\n",
       "      <td>59.0</td>\n",
       "      <td>delivery</td>\n",
       "      <td>148</td>\n",
       "      <td>get</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>heard</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>steal</td>\n",
       "      <td>17.0</td>\n",
       "      <td>see</td>\n",
       "      <td>7.0</td>\n",
       "      <td>work</td>\n",
       "      <td>30.0</td>\n",
       "      <td>human</td>\n",
       "      <td>21.0</td>\n",
       "      <td>future</td>\n",
       "      <td>32.0</td>\n",
       "      <td>take</td>\n",
       "      <td>81</td>\n",
       "      <td>time</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>know</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nice</td>\n",
       "      <td>1.0</td>\n",
       "      <td>going</td>\n",
       "      <td>10.0</td>\n",
       "      <td>right</td>\n",
       "      <td>5.0</td>\n",
       "      <td>bot</td>\n",
       "      <td>18.0</td>\n",
       "      <td>time</td>\n",
       "      <td>13.0</td>\n",
       "      <td>someone</td>\n",
       "      <td>21.0</td>\n",
       "      <td>seen</td>\n",
       "      <td>51</td>\n",
       "      <td>end</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>better</td>\n",
       "      <td>1.0</td>\n",
       "      <td>wonderfully</td>\n",
       "      <td>3.0</td>\n",
       "      <td>point</td>\n",
       "      <td>10.0</td>\n",
       "      <td>experience</td>\n",
       "      <td>5.0</td>\n",
       "      <td>car</td>\n",
       "      <td>18.0</td>\n",
       "      <td>deliver</td>\n",
       "      <td>13.0</td>\n",
       "      <td>taking</td>\n",
       "      <td>21.0</td>\n",
       "      <td>steal</td>\n",
       "      <td>50</td>\n",
       "      <td>love</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>option</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cute</td>\n",
       "      <td>1.0</td>\n",
       "      <td>year</td>\n",
       "      <td>10.0</td>\n",
       "      <td>video</td>\n",
       "      <td>5.0</td>\n",
       "      <td>cool</td>\n",
       "      <td>17.0</td>\n",
       "      <td>drone</td>\n",
       "      <td>13.0</td>\n",
       "      <td>order</td>\n",
       "      <td>21.0</td>\n",
       "      <td>long</td>\n",
       "      <td>49</td>\n",
       "      <td>fun</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>proving</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pick</td>\n",
       "      <td>8.0</td>\n",
       "      <td>easy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>stupid</td>\n",
       "      <td>14.0</td>\n",
       "      <td>imagine</td>\n",
       "      <td>10.0</td>\n",
       "      <td>help</td>\n",
       "      <td>17.0</td>\n",
       "      <td>love</td>\n",
       "      <td>42</td>\n",
       "      <td>coop</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>succes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>good</td>\n",
       "      <td>8.0</td>\n",
       "      <td>traffic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fedex</td>\n",
       "      <td>14.0</td>\n",
       "      <td>know</td>\n",
       "      <td>10.0</td>\n",
       "      <td>day</td>\n",
       "      <td>17.0</td>\n",
       "      <td>got</td>\n",
       "      <td>42</td>\n",
       "      <td>see</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>give</td>\n",
       "      <td>1.0</td>\n",
       "      <td>love</td>\n",
       "      <td>8.0</td>\n",
       "      <td>even</td>\n",
       "      <td>4.0</td>\n",
       "      <td>kick</td>\n",
       "      <td>14.0</td>\n",
       "      <td>make</td>\n",
       "      <td>10.0</td>\n",
       "      <td>guy</td>\n",
       "      <td>17.0</td>\n",
       "      <td>stolen</td>\n",
       "      <td>42</td>\n",
       "      <td>seeing</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>apparently</td>\n",
       "      <td>1.0</td>\n",
       "      <td>already</td>\n",
       "      <td>7.0</td>\n",
       "      <td>year</td>\n",
       "      <td>4.0</td>\n",
       "      <td>camera</td>\n",
       "      <td>13.0</td>\n",
       "      <td>want</td>\n",
       "      <td>9.0</td>\n",
       "      <td>well</td>\n",
       "      <td>16.0</td>\n",
       "      <td>getting</td>\n",
       "      <td>38</td>\n",
       "      <td>well</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2015_word  2015_frequency    2016_word  2016_frequency 2017_word   \n",
       "0     flying             4.0        robot            10.0     robot  \\\n",
       "7       good             1.0       pretty             3.0  delivery   \n",
       "18     heard             1.0          bad             2.0     steal   \n",
       "38      know             1.0         nice             1.0     going   \n",
       "39    better             1.0  wonderfully             3.0     point   \n",
       "40    option             1.0         cute             1.0      year   \n",
       "55       NaN             NaN      proving             1.0      pick   \n",
       "56       NaN             NaN       succes             1.0      good   \n",
       "57       NaN             NaN         give             1.0      love   \n",
       "65       NaN             NaN   apparently             1.0   already   \n",
       "\n",
       "    2017_frequency   2018_word  2018_frequency 2019_word  2019_frequency   \n",
       "0            137.0       robot            53.0     robot           148.0  \\\n",
       "7             29.0        like            10.0      take            46.0   \n",
       "18            17.0         see             7.0      work            30.0   \n",
       "38            10.0       right             5.0       bot            18.0   \n",
       "39            10.0  experience             5.0       car            18.0   \n",
       "40            10.0       video             5.0      cool            17.0   \n",
       "55             8.0        easy             4.0    stupid            14.0   \n",
       "56             8.0     traffic             4.0     fedex            14.0   \n",
       "57             8.0        even             4.0      kick            14.0   \n",
       "65             7.0        year             4.0    camera            13.0   \n",
       "\n",
       "   2020_word  2020_frequency 2021_word  2021_frequency 2022_word   \n",
       "0      robot           140.0     robot           214.0     robot  \\\n",
       "7        job            33.0      food            59.0  delivery   \n",
       "18     human            21.0    future            32.0      take   \n",
       "38      time            13.0   someone            21.0      seen   \n",
       "39   deliver            13.0    taking            21.0     steal   \n",
       "40     drone            13.0     order            21.0      long   \n",
       "55   imagine            10.0      help            17.0      love   \n",
       "56      know            10.0       day            17.0       got   \n",
       "57      make            10.0       guy            17.0    stolen   \n",
       "65      want             9.0      well            16.0   getting   \n",
       "\n",
       "    2022_frequency 2023_word  2023_frequency  \n",
       "0              477     robot            82.0  \n",
       "7              148       get            15.0  \n",
       "18              81      time            10.0  \n",
       "38              51       end             6.0  \n",
       "39              50      love             6.0  \n",
       "40              49       fun             6.0  \n",
       "55              42      coop             5.0  \n",
       "56              42       see             5.0  \n",
       "57              42    seeing             5.0  \n",
       "65              38      well             5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year in range(2015, 2024):\n",
    "    word_column = f'{year}_word'\n",
    "    if word_column in df.columns:\n",
    "        df = df[~df[word_column].isin(drop_list)]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('word_frequency_by_year_2015_2023_cleaned.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Yuchen\n",
      "[nltk_data]     Du\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Yuchen Du\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Yuchen\n",
      "[nltk_data]     Du\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_dict = {\n",
    "    'robot': ['automaton', 'android', 'cyborg'],\n",
    "    'people': ['individuals', 'persons', 'humans'],\n",
    "    'steal': ['pilfer', 'thieve', 'swipe'],\n",
    "    'wonderful': ['marvelous', 'remarkable', 'magnificent'],\n",
    "    'nice': ['pleasant', 'agreeable', 'delightful'],\n",
    "    'cute': ['adorable', 'charming', 'endearing']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(2015, 2024):\n",
    "    word_column = f'{year}_word'\n",
    "    freq_column = f'{year}_frequency'\n",
    "\n",
    "    if word_column in df.columns and freq_column in df.columns:\n",
    "        for word, synonyms in synonyms_dict.items():\n",
    "            for synonym in synonyms:\n",
    "                if synonym in df[word_column].values:\n",
    "                    df.loc[df[word_column] == word, freq_column] += df.loc[df[word_column] == synonym, freq_column]\n",
    "                    df = df[df[word_column] != synonym]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
