# coding: utf-8
'''
filename: word2vec_downloader.py
function: Word2Vec model download and management
'''

import os
import gdown
import requests
from urllib.parse import urlparse
from gensim.models import KeyedVectors
import zipfile

class Word2VecDownloader:
    """Word2Vec model downloader"""
    
    def __init__(self, model_dir='data'):
        self.model_dir = model_dir
        self.model_path = os.path.join(model_dir, 'GoogleNews-vectors-negative300.bin')
        
        # Ensure directory exists
        if not os.path.exists(model_dir):
            os.makedirs(model_dir)
    
    def check_model_exists(self):
        """Check if model file exists"""
        return os.path.exists(self.model_path)
    
    def verify_model_integrity(self):
        """Verify model file integrity"""
        if not self.check_model_exists():
            return False
        
        try:
            # Check file size (GoogleNews model should be about 1.6GB)
            file_size = os.path.getsize(self.model_path)
            if file_size < 1000000000:  # Less than 1GB indicates incomplete download
                print(f"Model file size abnormal: {file_size} bytes (expected > 1GB)")
                return False
            
            # Try to read file header
            with open(self.model_path, 'rb') as f:
                header = f.read(100)
                if len(header) < 10:
                    print("Model file header read failed")
                    return False
            
            print(f"Model file integrity check passed: {file_size} bytes")
            return True
            
        except Exception as e:
            print(f"Model integrity verification failed: {e}")
            return False
    
    def fix_encoding_issues(self):
        """Fix encoding issues"""
        print("Attempting to fix Word2Vec encoding issues...")
        
        # Method 1: Load with different encoding parameters
        encoding_methods = [
            {'binary': True, 'unicode_errors': 'ignore'},
            {'binary': True, 'encoding': 'utf-8', 'unicode_errors': 'ignore'},
            {'binary': True, 'encoding': 'latin-1'},
            {'binary': False, 'encoding': 'utf-8', 'unicode_errors': 'ignore'},
        ]
        
        for i, params in enumerate(encoding_methods):
            try:
                print(f"Attempting loading method {i+1}: {params}")
                model = KeyedVectors.load_word2vec_format(self.model_path, **params)
                print(f"âœ“ Loading successful! Vocabulary size: {len(model.key_to_index)}")
                return model
            except Exception as e:
                print(f"âœ— Method {i+1} failed: {e}")
                continue
        
        return None
    
    def backup_and_redownload(self):
        """Backup corrupted files and redownload"""
        if self.check_model_exists():
            # Backup corrupted files
            backup_path = self.model_path + '.corrupted'
            try:
                os.rename(self.model_path, backup_path)
                print(f"Corrupted file backed up to: {backup_path}")
            except:
                os.remove(self.model_path)
                print("Corrupted file deleted")

        # Redownload
        print("Starting to redownload Word2Vec model...")
        return self.download_model()

    def download_from_google_drive(self, file_id='0B7XkCwpI5KDYNlNUTTlSS21pQmM'):
        """Download Word2Vec model from Google Drive"""
        print("Downloading Word2Vec model from Google Drive...")
        url = f'https://drive.google.com/uc?id={file_id}'
        
        try:
            # Download file
            output_path = self.model_path
            gdown.download(url, output_path, quiet=False)
            print(f"Model download completed: {output_path}")
            return True
        except Exception as e:
            print(f"Download from Google Drive failed: {e}")
            return False
    
    def download_from_alternative_source(self):
        """Download Word2Vec model from alternative source"""
        print("Downloading Word2Vec model from alternative source...")
        
        # Alternative download links (this is an example, valid links are needed for actual use)
        urls = [
            'https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz',
            # Can add more alternative links
        ]
        
        for url in urls:
            try:
                print(f"Attempting to download from {url}...")
                response = requests.get(url, stream=True)
                
                if response.status_code == 200:
                    # If it's a compressed file, need to decompress
                    if url.endswith('.gz'):
                        import gzip
                        output_path = self.model_path + '.gz'
                        
                        with open(output_path, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                f.write(chunk)
                        
                        # Decompress file
                        with gzip.open(output_path, 'rb') as f_in:
                            with open(self.model_path, 'wb') as f_out:
                                f_out.write(f_in.read())
                        
                        # Delete compressed file
                        os.remove(output_path)
                    else:
                        with open(self.model_path, 'wb') as f:
                            for chunk in response.iter_content(chunk_size=8192):
                                f.write(chunk)
                    
                    print(f"Model download completed: {self.model_path}")
                    return True
                    
            except Exception as e:
                print(f"Download from {url} failed: {e}")
                continue
        
        return False
    
    def download_smaller_model(self):
        """Download smaller Word2Vec model as alternative"""
        print("Downloading smaller Word2Vec model...")
        
        try:
            import gensim.downloader as api
            # Download smaller word2vec model
            model = api.load('word2vec-google-news-300')
            
            # Save as binary format
            model.save_word2vec_format(self.model_path, binary=True)
            print(f"å°åž‹æ¨¡åž‹ä¸‹è½½å®Œæˆ: {self.model_path}")
            return True
            
        except Exception as e:
            print(f"ä¸‹è½½å°åž‹æ¨¡åž‹å¤±è´¥: {e}")
            return False
    
    def create_dummy_model(self):
        """åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„å°åž‹æ¨¡åž‹ä¾›æµ‹è¯•ä½¿ç”¨"""
        print("åˆ›å»ºè™šæ‹ŸWord2Vecæ¨¡åž‹ä¾›æµ‹è¯•...")
        
        try:
            from gensim.models import Word2Vec
            import nltk
            from nltk.tokenize import word_tokenize
            
            # åˆ›å»ºä¸€äº›ç¤ºä¾‹å¥å­
            sentences = [
                "this is good delivery robot service",
                "this is bad delivery experience", 
                "delivery robot is great and amazing",
                "delivery service excellent wonderful",
                "poor delivery experience terrible",
                "amazing delivery robot fantastic",
                "terrible service quality horrible",
                "wonderful delivery experience perfect",
                "robot automation technology future",
                "sidewalk delivery autonomous vehicle",
                "safety concern pedestrian traffic",
                "job displacement unemployment worry",
                "convenient efficient fast delivery",
                "innovative technology advancement",
                "negative positive neutral sentiment"
            ]
            
            # åˆ†è¯
            tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]
            
            # è®­ç»ƒå°åž‹Word2Vecæ¨¡åž‹
            model = Word2Vec(tokenized_sentences, vector_size=300, window=5, min_count=1, workers=4, epochs=10)
            
            # ä¿å­˜æ¨¡åž‹
            model.wv.save_word2vec_format(self.model_path, binary=True)
            print(f"è™šæ‹Ÿæ¨¡åž‹åˆ›å»ºå®Œæˆ: {self.model_path}")
            return True
            
        except Exception as e:
            print(f"åˆ›å»ºè™šæ‹Ÿæ¨¡åž‹å¤±è´¥: {e}")
            return False
    
    def download_model(self, method='auto'):
        """
        ä¸‹è½½Word2Vecæ¨¡åž‹
        
        Args:
            method: ä¸‹è½½æ–¹æ³• ('google_drive', 'alternative', 'small', 'dummy', 'auto')
        """
        if self.check_model_exists():
            print(f"Word2Vecæ¨¡åž‹å·²å­˜åœ¨: {self.model_path}")
            return True
        
        print("Word2Vecæ¨¡åž‹ä¸å­˜åœ¨ï¼Œå¼€å§‹ä¸‹è½½...")
        
        if method == 'auto':
            # è‡ªåŠ¨å°è¯•å„ç§æ–¹æ³•
            methods = ['google_drive', 'alternative', 'small', 'dummy']
        else:
            methods = [method]
        
        for method in methods:
            print(f"\nå°è¯•æ–¹æ³•: {method}")
            
            if method == 'google_drive':
                if self.download_from_google_drive():
                    return True
            elif method == 'alternative':
                if self.download_from_alternative_source():
                    return True
            elif method == 'small':
                if self.download_smaller_model():
                    return True
            elif method == 'dummy':
                if self.create_dummy_model():
                    return True
        
        print("æ‰€æœ‰ä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥äº†")
        return False
    
    def load_model(self, fix_encoding=True):
        """åŠ è½½Word2Vecæ¨¡åž‹"""
        if not self.check_model_exists():
            print("æ¨¡åž‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½")
            return None
        
        # é¦–å…ˆéªŒè¯æ–‡ä»¶å®Œæ•´æ€§
        if not self.verify_model_integrity():
            print("æ¨¡åž‹æ–‡ä»¶æŸåï¼Œå°è¯•é‡æ–°ä¸‹è½½...")
            if self.backup_and_redownload():
                # é‡æ–°ä¸‹è½½æˆåŠŸï¼Œç»§ç»­åŠ è½½
                pass
            else:
                print("é‡æ–°ä¸‹è½½å¤±è´¥")
                return None
        
        # å°è¯•æ ‡å‡†åŠ è½½
        try:
            print("æ­£åœ¨åŠ è½½Word2Vecæ¨¡åž‹...")
            model = KeyedVectors.load_word2vec_format(self.model_path, binary=True)
            print("Word2Vecæ¨¡åž‹åŠ è½½æˆåŠŸ")
            return model
        except Exception as e:
            print(f"æ ‡å‡†åŠ è½½å¤±è´¥: {e}")
            
            # å¦‚æžœå¯ç”¨ç¼–ç ä¿®å¤ï¼Œå°è¯•ä¿®å¤
            if fix_encoding:
                print("å°è¯•ä¿®å¤ç¼–ç é—®é¢˜...")
                model = self.fix_encoding_issues()
                if model is not None:
                    return model
                
                # å¦‚æžœä¿®å¤å¤±è´¥ï¼Œå°è¯•é‡æ–°ä¸‹è½½å°åž‹æ¨¡åž‹
                print("ç¼–ç ä¿®å¤å¤±è´¥ï¼Œå°è¯•ä¸‹è½½å°åž‹æ¨¡åž‹...")
                if self.backup_and_redownload():
                    try:
                        model = KeyedVectors.load_word2vec_format(self.model_path, binary=True)
                        print("é‡æ–°ä¸‹è½½åŽåŠ è½½æˆåŠŸ")
                        return model
                    except:
                        pass
                
                # æœ€åŽå°è¯•åˆ›å»ºè™šæ‹Ÿæ¨¡åž‹
                print("åˆ›å»ºè™šæ‹Ÿæ¨¡åž‹ä½œä¸ºæœ€åŽæ‰‹æ®µ...")
                if self.create_dummy_model():
                    try:
                        model = KeyedVectors.load_word2vec_format(self.model_path, binary=True)
                        print("è™šæ‹Ÿæ¨¡åž‹åŠ è½½æˆåŠŸ")
                        return model
                    except:
                        pass
            
            print("æ‰€æœ‰åŠ è½½æ–¹æ³•éƒ½å¤±è´¥äº†")
            return None
    
    def get_model_info(self):
        """èŽ·å–æ¨¡åž‹ä¿¡æ¯"""
        if not self.check_model_exists():
            return None
        
        try:
            model = self.load_model()
            if model is not None:
                vocab_size = len(model.key_to_index)
                vector_size = model.vector_size
                return {
                    'vocab_size': vocab_size,
                    'vector_size': vector_size,
                    'model_path': self.model_path,
                    'file_size': os.path.getsize(self.model_path)
                }
        except Exception as e:
            print(f"èŽ·å–æ¨¡åž‹ä¿¡æ¯å¤±è´¥: {e}")
        
        return None

def download_word2vec_model(model_dir='data', method='auto'):
    """ä¾¿æ·å‡½æ•°ï¼šä¸‹è½½Word2Vecæ¨¡åž‹"""
    downloader = Word2VecDownloader(model_dir)
    return downloader.download_model(method)

def load_word2vec_model(model_dir='data', fix_encoding=True):
    """ä¾¿æ·å‡½æ•°ï¼šåŠ è½½Word2Vecæ¨¡åž‹"""
    downloader = Word2VecDownloader(model_dir)
    return downloader.load_model(fix_encoding=fix_encoding)

def fix_word2vec_encoding(model_dir='data'):
    """ä¾¿æ·å‡½æ•°ï¼šä¿®å¤Word2Vecç¼–ç é—®é¢˜"""
    downloader = Word2VecDownloader(model_dir)
    
    print("å¼€å§‹ä¿®å¤Word2Vecç¼–ç é—®é¢˜...")
    print("="*50)
    
    # æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
    if not downloader.check_model_exists():
        print("âŒ æ¨¡åž‹æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    # éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
    if not downloader.verify_model_integrity():
        print("âš ï¸ æ¨¡åž‹æ–‡ä»¶æŸå")
        if downloader.backup_and_redownload():
            print("âœ… é‡æ–°ä¸‹è½½å®Œæˆ")
        else:
            print("âŒ é‡æ–°ä¸‹è½½å¤±è´¥")
            return False
    
    # å°è¯•åŠ è½½
    model = downloader.load_model(fix_encoding=True)
    if model is not None:
        print("ðŸŽ‰ Word2Vecç¼–ç é—®é¢˜ä¿®å¤æˆåŠŸ!")
        print(f"ðŸ“Š æ¨¡åž‹ä¿¡æ¯: è¯æ±‡é‡={len(model.key_to_index)}, å‘é‡ç»´åº¦={model.vector_size}")
        return True
    else:
        print("âŒ Word2Vecç¼–ç é—®é¢˜ä¿®å¤å¤±è´¥")
        return False 